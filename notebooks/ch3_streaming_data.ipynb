{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alessandro, Email: alessandro.gauthier@example.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from docx.opc.constants import RELATIONSHIP_TYPE as RT\n",
    "import boto3\n",
    "import json\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "\n",
    "response = requests.get('https://randomuser.me/api/')\n",
    "data = response.json()\n",
    "\n",
    "# Access the data returned from the API\n",
    "results = data['results']\n",
    "for result in results:\n",
    "    first_name = result['name']['first']\n",
    "    last_name = result['name']['last']\n",
    "    age = result['age']\n",
    "    gender = result['gender']\n",
    "    lattitude = result['location']['coordinates']['latitude']\n",
    "    longitude = result['location']['coordinates']['longitude']\n",
    "\n",
    "    firehose_client = boto3.client('firehose')\n",
    "\n",
    "    # Convert the data dictionary to JSON string\n",
    "    json_data = json.dumps(data)\n",
    "\n",
    "    # Specify the delivery stream name\n",
    "    delivery_stream_name = 'your_delivery_stream_name'\n",
    "\n",
    "    # Put the JSON data to the delivery stream\n",
    "    response = firehose_client.put_record(\n",
    "        DeliveryStreamName=delivery_stream_name,\n",
    "        Record={\n",
    "            'Data': json_data.encode('utf-8')\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Check if the record was successfully put\n",
    "    if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "        print('JSON data successfully loaded to Kinesis Firehose')\n",
    "    else:\n",
    "        print('Failed to load JSON data to Kinesis Firehose')\n",
    "\n",
    "    \n",
    "    # print(f\"Name: {name}, Email: {email}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def upload_to_s3(file_name, bucket, object_name=None):\n",
    "    mime_type = mime.from_file(file_name) \n",
    "    s3.upload_file(\n",
    "        file_name, \n",
    "        bucket, \n",
    "        object_name or file_name,\n",
    "        ExtraArgs={\n",
    "        'ContentType': mime_type\n",
    "        })\n",
    "    return f\"https://{bucket}.s3.amazonaws.com/{object_name or file_name}\"\n",
    "\n",
    "\n",
    "def list_image_files(directory):\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "    return image_files\n",
    "\n",
    "\n",
    "def get_image_info_from_csv(df_csv, orig_filename):\n",
    "    \n",
    "    matching_line = df_csv[df_csv['file'] == orig_filename]\n",
    "    image_description = \"\"\n",
    "    if not matching_line.empty:\n",
    "        image_description = matching_line.iloc[0]['description'] or ''\n",
    "    return image_description\n",
    "\n",
    "\n",
    "if os.path.exists( INPUT_PATH ):\n",
    "\n",
    "    image_data = []\n",
    "    image_files = list_image_files(INPUT_PATH)\n",
    "    df_csv = pd.read_csv(CSV_INFO)    \n",
    "    for file in image_files:\n",
    "        try: \n",
    "            filename = os.path.basename(file)\n",
    "            folder = os.path.dirname(file)\n",
    "            desc = get_image_info_from_csv(df_csv, filename)\n",
    "            desc_path = os.path.join(folder, os.path.splitext(filename)[0])\n",
    "            path_desc = ' '.join(re.split(r'[^a-zA-Z@]+', desc_path))\n",
    "            desc = f\"{desc} {path_desc}\".strip()\n",
    "            url = upload_to_s3(file, IMAGE_BUCKET, filename)\n",
    "            csv_file = f'{filename}.csv'\n",
    "\n",
    "            \n",
    "            with open(csv_file, 'w+', newline='') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=[ 'image_description', 'image_url',])\n",
    "                writer.writeheader()\n",
    "                writer.writerow({'image_description': f'{desc}', 'image_url': url})\n",
    "            upload_to_s3(csv_file, IMAGE_REF_BUCKET)\n",
    "            os.remove(csv_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "        \n",
    "        print(f\"======================================================\")\n",
    "        print(f\"Processed... '{file.name}'\")\n",
    "        print(f\"\\timage uploaded s3://{IMAGE_BUCKET}/{filename}\")\n",
    "        print(f\"\\tdescription created '{desc}'\")\n",
    "        print(f\"\\tcsv uploaded s3://{IMAGE_REF_BUCKET}/{csv_file}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Directory '{INPUT_PATH}' does not exist.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
